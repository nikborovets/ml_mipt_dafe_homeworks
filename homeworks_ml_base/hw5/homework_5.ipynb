{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d57f64ef-ec87-48fa-a375-3bcb54efe6c1",
   "metadata": {},
   "source": [
    "# Домашнее задание № 6\n",
    "\n",
    "Сегодня мы будем  своими руками реализовывать градиентный бустинг на основе вычисления Lambda! \n",
    "\n",
    "В качестве базового алгоритма для бустинга будем использовать ```DecisionTreeRegressor``` из библиотеки ```sklearn```. Как было сказано в лекции, единственное существенное отличие — это целевые метки, на которые обучается каждое дерево: вместо типичных для бустинга ошибок (невязок) используются Lambda-значения. Функцию вычисления лямбд мы рассмотрели на практическом занятии. В решение необходимо осмысленно перенести реализацию в метод ```_compute_lambdas``` класса ```Solution```. \n",
    "\n",
    "## Параметры класса\n",
    "```n_estimators``` — количество деревьев, которые будут строиться в рамках бустинга.\n",
    "\n",
    "```lr``` — Learning Rate, коэффициент, на который умножаются предсказания каждого нового дерева в алгоритме (каждое дерево учится предсказывать значение lambda, но не факт, что добавление к текущим предсказаниям такого значения даст оптимум, поэтому весь “путь” оптимизации разбивается на маленькие шаги).\n",
    "\n",
    "```subsample``` — доля объектов от выборки, на которых обучается каждое дерево (доля одинакова для всех деревьев, но сама подвыборка генерируется на каждом шаге отдельно).\n",
    "\n",
    "```colsample_bytree``` — доля признаков от выборки, на которых обучается каждое дерево (доля одинакова для всех деревьев, но сама подвыборка генерируется на каждом шаге отдельно).\n",
    "\n",
    "Совокупность двух вышеуказанных параметров позволяет реализовать метод случайных подпространств (смотрите описание по ссылке при необходимости). Понятно, что для применения деревьев (получения предсказания) нужно хранить индексы использованных признаков (но не объектов).\n",
    "\n",
    "```max_depth``` и ```min_samples_leaf``` — параметры ```DecisionTreeRegressor```, отвечающие за глубину построения дерева и минимальное количество в терминальных (финальных) листьях дерева соответственно. \n",
    "\n",
    "## Методы класса\n",
    "```_get_data```, ```_prepare_data```, ```_scale_features_in_query_groups```, ```_ndcg_k``` уже знакомы — можно перенести их реализацию  с тем лишь отличием, что для удобства срезов по индексам размерности ```ys_train``` и ```ys_test``` должны быть N∗1, где N-количество объектов (без этого грейдер будет отчитываться об ошибке).\n",
    "\n",
    "```save_model``` и ```load_model``` — методы, отвечающие за сохранение и загрузку модели. Вам необходимо самостоятельно определить набор полей (их минимум 3), которые нужно сохранять после тренировки и загружать для предсказания. После ```load_model``` необходимо добиться, чтобы модель могла давать те же самые предсказания, что и до сохранения. Сохранение и загрузку реализуйте через модуль ```pickle```. Пример:\n",
    "\n",
    "```bash\n",
    "state = {…}\n",
    "f = open(path, 'wb')\n",
    "pickle.dump(state, f)\n",
    "```\n",
    "\n",
    "Предсказания формируются в методе ```predict```. На вход поступает тензор данных размерности N∗D, где N — количество объектов, D — количество признаков. На выходе ожидается применённый алгоритм бустинга, т.е. тензор предсказаний.\n",
    "\n",
    "Расчёт метрики по набору данных должен производиться методом ```_calc_data_ndcg``` — в нём необходимо проитерироваться по группам запросов, посчитав в каждой ```NDCG```, после чего вернуть усреднённое значение метрики.\n",
    "\n",
    "## Методы для тренировки\n",
    "```_train_one_tree``` — метод для тренировки одного дерева. Принимает на вход ```cur_tree_idx``` — номер текущего дерева, который предлагается использовать в качестве random_seed для того, чтобы алгоритм был детерминирован. ```train_preds``` — суммарные предсказания всех предыдущих деревьев (для расчёта лямбд). В рамках метода необходимо рассчитать лямбды для каждой группы в тренировочном наборе данных, затем применить метод случайных подпространств, сделав срез по признакам (случайно выбранная группа, размер которой задан параметром ```colsample_bytree```) и по объектам (тоже случайно выбранная группа, размер зависит от параметра subsample). Затем произвести тренировку одного ```DecisionTreeRegressor```. Возвращаемые значения — это само дерево и индексы признаков, на которых обучалось дерево.\n",
    "\n",
    "```fit``` — генеральный метод обучения K деревьев, каждое из которых тренируется с использованием метода ```_train_one_tree```. Изначальные предсказания до обучения предлагается приравнять к нулю и от этих значений отталкиваться при обучении первого дерева. Все обученные деревья необходимо сохранить в список, хранящийся в атрибуте trees класса ```Solution```. Для простоты и ускорения работы предлагается рассчитывать предсказания для всех тренировочных и валидационных данных после обучения каждого дерева (но досчитывать только изменения за последнее дерево, храня в памяти предсказания всех предыдущих). Следите за лучшим значением ```NDCG``` (хранить в переменной ```best_ndcg```) — после окончания тренировки нужно обрезать те последние N деревьев, которые лишь ухудшают метрику на валидации. Например, вы обучили 100 деревьев, и лучший результат был достигнут на 78-м. Тогда ```self.trees``` нужно обрезать до 78-го дерева, чтобы модель при предсказании работала лучше всего.\n",
    "\n",
    "## Критерии оценки\n",
    "- Корректная предобработка данных.\n",
    "- Модель адекватно отработала на 1 дереве, ```NDCG``` выше порога случайных предсказаний.\n",
    "- Модель на 100 деревьев на подложенных данных обучается, ```NDCG≥0.425```.\n",
    "- Обученная и сохраненная модель после загрузки корректно дала предсказания в методе ```predict```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5c4dd4-0800-4300-ab75-3805849aa2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hw6_solved import Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e092e15c-05d9-4ac8-9b75-c9c1e485be75",
   "metadata": {},
   "source": [
    "# Запуск и сохранение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5604709-0971-45ad-a173-847e4796f259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8570f8383bab4ee0a6adc48deb3842ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best test ndcg: 0.433 (179)\n"
     ]
    }
   ],
   "source": [
    "sol = Solution()\n",
    "sol.fit()\n",
    "sol.load_model(\"model.pckl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e721bd90-fd8d-44d2-8378-6aa6a6dc9a05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0506c2-1b94-4bdc-a581-806340553db2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
