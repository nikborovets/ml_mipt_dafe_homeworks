{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjl6x6og3uXH"
   },
   "source": [
    "# HW 2 - Разложение матриц градиентным методом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sv79QFb_-oNZ"
   },
   "source": [
    "Цель задания: В ходе реализации [разложения Таккера](https://proceedings.neurips.cc/paper/2018/file/45a766fa266ea2ebeb6680fa139d2a3d-Paper.pdf) градиентным методом освоить pyTorch и реализовать подходы оптимизации параметров модели (в отсутствии готовых решений)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1HUSrylpBwYn"
   },
   "source": [
    "[Более-менее внятное описание алгоритма канонического разложения](https://www.alexejgossmann.com/tensor_decomposition_tucker/) - само аналитическое разложение вам реализовывать НЕ НУЖНО"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "P1PuoBtG7iw7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10af240b0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse.linalg import spsolve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.linalg import svd, matrix_rank, pinv, inv\n",
    "from scipy.linalg import eigh, eig\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tqdm.notebook import tqdm\n",
    "from torch import nn\n",
    "\n",
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6LfhKpuX7htE"
   },
   "source": [
    "## 1 Создайте 3х мерный тензор\n",
    "Размер тензора не меньше 100 по каждой из размерностей.\n",
    "\n",
    "Заполните случайными целыми числами в диапазоне от 0 до 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ap1Ozn7P8-Yj"
   },
   "source": [
    "Примечание: разложение будет корректно работать со случайным тензором, только если изначально создавать случайные ядро и матрицы, а потом по ним формировать тензор. Работайте с типом *torch.Tensor.double*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "5SzHzteOROQQ"
   },
   "outputs": [],
   "source": [
    "# Создадим тензор: размер тензора и r задаётся\n",
    "def get_tensor(size=(100,200,150), r=(10, 10, 10)):\n",
    "  # data - тензор с заданной размерностью\n",
    "  # U - список матриц\n",
    "  # G - ядро разложения\n",
    "    \n",
    "  U = [torch.randn(size[i], r[i], dtype=torch.double) for i in range(len(size))]\n",
    "  \n",
    "  G = torch.randn(*r, dtype=torch.double)\n",
    "  \n",
    "  data = G.clone()\n",
    "  for i in range(len(size)):\n",
    "      data = torch.tensordot(data, U[i], dims=([0], [1]))\n",
    "  \n",
    "  return data, U, G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EFuFlp2n78Tz"
   },
   "source": [
    "Сгенерируйте тензор и добавьте к нему случайный шум с размерностью *1e-2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "FnUbbsYSdrsw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 200, 300]),\n",
       " [torch.Size([100, 10]), torch.Size([200, 10]), torch.Size([300, 10])],\n",
       " torch.Size([10, 10, 10]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = (100, 200, 300)\n",
    "r=(10, 10, 10)\n",
    "\n",
    "data, U, G = get_tensor(size, r)\n",
    "data.shape, [u.shape for u in U], G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "N70Xy_6u9RFa"
   },
   "outputs": [],
   "source": [
    "noise = torch.randn_like(data) * 1e-2\n",
    "data_noisy = data + noise\n",
    "data_noisy = (data_noisy - data_noisy.mean()) / data_noisy.std()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kp75_Ad29RL5"
   },
   "source": [
    "Вопрос:\n",
    "Почему задание не имеет смысла для полностью случайного тензора и зачем добавлять шум? *не отвечать нельзя*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5VLMaT5wyE11"
   },
   "source": [
    "Ответ:\n",
    "\n",
    "    - Если тензор полностью случайный, то теряется цель разложения — выделение закономерностей и зависимостей.\n",
    "    - Шум добавляют, чтобы имитировать реальные данные с погрешностями и сделать алгоритм более устойчивым. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TzninpMYD_hd"
   },
   "source": [
    "## 2 Реализуйте метод для восстановления тензора по разложению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "YDTx9ZbYD-_S"
   },
   "outputs": [],
   "source": [
    "# Функция, восстанавливающая тензор по ядру и матрицам\n",
    "def repair_tensor(G_, U):\n",
    "  # data - восстановленный тензор из матриц и ядра\n",
    "  # U - список матриц\n",
    "  # G_ - ядро разложения\n",
    "  \n",
    "  data = G_.clone()\n",
    "  for i in range(len(U)):\n",
    "      data = torch.tensordot(data, U[i], dims=([0], [1]))\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "KvEKNuTvIIfp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 200, 300])\n",
      "MSE: 0.0\n"
     ]
    }
   ],
   "source": [
    "restored_data = repair_tensor(G, U)\n",
    "\n",
    "print(restored_data.shape)\n",
    "\n",
    "mse = torch.mean((restored_data - data) ** 2).item()\n",
    "print(f\"MSE: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKqzxtaE-F16"
   },
   "source": [
    "## 3 Сделайте разложение библиотечным методом\n",
    "Пакет можете брать любой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "Hlp4Jh3--fKh"
   },
   "outputs": [],
   "source": [
    "tl_data = tl.tensor(data_noisy.numpy())\n",
    "\n",
    "rank = (10, 10, 10)\n",
    "core, factors = tucker(tl_data, rank)\n",
    "\n",
    "restored_tl_data = tl.tucker_to_tensor((core, factors))\n",
    "\n",
    "restored_torch_data = torch.tensor(restored_tl_data, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wMw1x8w8-lsh"
   },
   "source": [
    "Не забудьте померить ошибку разложения по метрике MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "HWkdb7Ip-mL3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE между оригинальным и восстановленным тензором: 1.0347827097420307e-07\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(data_noisy.flatten().numpy(), restored_torch_data.flatten().numpy())\n",
    "\n",
    "print(f\"MSE между оригинальным и восстановленным тензором: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibOgeEgfD1wm"
   },
   "source": [
    "## 4 Реализуйте разложение градиентным методом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GstBYmiBF7A6"
   },
   "source": [
    "### 4.1 Реализуйте *optimizer*\n",
    "Можно взять из исходников *PyTorch* и отнаследоваться от *torch.optim.optimizer*.\n",
    "Используйте квадратичный *Loss*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "Mxrtt60hF6xb"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "class Opt(Optimizer):\n",
    "    def __init__(self, params, lr=1e-3):\n",
    "\n",
    "        defaults = dict(lr=lr)\n",
    "        super().__init__(params, defaults)\n",
    "        \n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for param in group['params']:\n",
    "                if param.grad is None:\n",
    "                    continue\n",
    "\n",
    "                grad = param.grad.data\n",
    "\n",
    "                param.data -= group['lr'] * grad\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GSolH5dEJba"
   },
   "source": [
    "### 4.2 Реализуйте цикл оптимизации параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6UWpuERFTn8"
   },
   "source": [
    "Стоит параметры оптимизировать сразу на GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "CgPaeQ7XEJnD"
   },
   "outputs": [],
   "source": [
    "def optimize_tucker(data, rank, num_epochs=1000, lr=1e-3, device=\"cpu\"):\n",
    "    data = data.to(device)\n",
    "    \n",
    "    G = torch.randn(*rank, dtype=torch.double, requires_grad=True, device=device)\n",
    "    U = [torch.randn(data.size(i), rank[i], dtype=torch.double, requires_grad=True, device=device) \n",
    "         for i in range(len(rank))]\n",
    "    \n",
    "    params = [G] + U\n",
    "\n",
    "    optimizer = Opt(params, lr=lr)\n",
    "\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            reconstructed = G.clone()\n",
    "            for i in range(len(U)):\n",
    "                reconstructed = torch.tensordot(reconstructed, U[i], dims=([0], [1]))\n",
    "\n",
    "            reg_factor = 1e-4\n",
    "            loss = loss_fn(reconstructed, data) + reg_factor * (torch.norm(G) + sum(torch.norm(u) for u in U))\n",
    "            loss.backward()\n",
    "            return loss\n",
    "\n",
    "        loss = optimizer.step(closure)\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}/{num_epochs}, Loss: {loss.item():.2f}\")\n",
    "\n",
    "    reconstructed = G.clone()\n",
    "    for i in range(len(U)):\n",
    "        reconstructed = torch.tensordot(reconstructed, U[i], dims=([0], [1]))\n",
    "\n",
    "    return reconstructed, G, U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000, Loss: 1002.97\n",
      "Epoch 100/1000, Loss: 400.84\n",
      "Epoch 200/1000, Loss: 230.54\n",
      "Epoch 300/1000, Loss: 154.10\n",
      "Epoch 400/1000, Loss: 111.97\n",
      "Epoch 500/1000, Loss: 85.82\n",
      "Epoch 600/1000, Loss: 68.30\n",
      "Epoch 700/1000, Loss: 55.88\n",
      "Epoch 800/1000, Loss: 46.71\n",
      "Epoch 900/1000, Loss: 39.72\n",
      "MSE после оптимизации: 34.25\n"
     ]
    }
   ],
   "source": [
    "rank = (10, 10, 10)\n",
    "num_epochs = 1000\n",
    "lr = 1e-3\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "restored_tensor, G_optimized, U_optimized = optimize_tucker(data_noisy, rank, num_epochs, lr, device)\n",
    "\n",
    "mse = torch.mean((restored_tensor - data_noisy) ** 2).item()\n",
    "print(f\"MSE после оптимизации: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Za8JKgR-Falk"
   },
   "source": [
    "## 5 Приведите сравнение скорости работы и ошибки восстановления методом из пакета и реализованного градиентного\n",
    "Сравнение может считаться ± объективным с размером выборки от 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "mOGKW9RHFa5D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorly: Время=2.4710 сек, MSE=0.000000\n",
      "Epoch 0/1000, Loss: 982.88\n",
      "Epoch 100/1000, Loss: 389.03\n",
      "Epoch 200/1000, Loss: 223.34\n",
      "Epoch 300/1000, Loss: 149.14\n",
      "Epoch 400/1000, Loss: 108.27\n",
      "Epoch 500/1000, Loss: 82.93\n",
      "Epoch 600/1000, Loss: 65.93\n",
      "Epoch 700/1000, Loss: 53.89\n",
      "Epoch 800/1000, Loss: 45.01\n",
      "Epoch 900/1000, Loss: 38.24\n",
      "Градиентный метод: Время=30.5879 сек, MSE=32.929582\n"
     ]
    }
   ],
   "source": [
    "def compare_methods(data, rank, num_epochs=1000, lr=1e-3, device=\"cuda\"):\n",
    "    start_time = time.time()\n",
    "    tl_data = tl.tensor(data.numpy())\n",
    "    core, factors = tucker(tl_data, rank)\n",
    "    restored_tl = tl.tucker_to_tensor((core, factors))\n",
    "    tl_time = time.time() - start_time\n",
    "    tl_mse = mean_squared_error(data.numpy().flatten(), restored_tl.flatten())\n",
    "    \n",
    "    print(f\"Tensorly: Время={tl_time:.4f} сек, MSE={tl_mse:.6f}\")\n",
    "\n",
    "    start_time = time.time()\n",
    "    restored_grad, _, _ = optimize_tucker(data, rank, num_epochs, lr, device)\n",
    "    grad_time = time.time() - start_time\n",
    "    grad_mse = torch.mean((restored_grad - data) ** 2).item()\n",
    "\n",
    "    print(f\"Градиентный метод: Время={grad_time:.4f} сек, MSE={grad_mse:.6f}\")\n",
    "\n",
    "    results = {\n",
    "        \"Method\": [\"Tensorly\", \"Gradient\"],\n",
    "        \"Time (sec)\": [tl_time, grad_time],\n",
    "        \"MSE\": [tl_mse, grad_mse],\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "rank = (10, 10, 10)\n",
    "num_epochs = 1000\n",
    "lr = 1e-3\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "comparison_results = compare_methods(data_noisy, rank, num_epochs, lr, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
