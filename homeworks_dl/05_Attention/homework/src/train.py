# from seminar_code: training loop with Label Smoothing (Task 5) and ROUGE metrics (Task 2)
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
import numpy as np
from rouge_score import rouge_scorer
import math
import os
import json
import argparse
from datetime import datetime
from torch.utils.tensorboard import SummaryWriter
from .data import load_processed_data_iterators, convert_batch
from .model import create_model, create_model_with_pretrained_embeddings
from . import get_device


class LabelSmoothingLoss(nn.Module):
    """
    Label Smoothing Loss (–ó–∞–¥–∞–Ω–∏–µ 5).
    –°–≥–ª–∞–∂–∏–≤–∞–µ—Ç –∏—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –æ–±–æ–±—â–µ–Ω–∏—è.
    """
    def __init__(self, size, padding_idx, smoothing=0.1):
        super().__init__()
        self.criterion = nn.KLDivLoss(reduction='sum')
        self.padding_idx = padding_idx
        self.confidence = 1.0 - smoothing
        self.smoothing = smoothing
        self.size = size
        self.true_dist = None

    def forward(self, x, target):
        """
        –ü—Ä–∏–º–µ–Ω—è–µ—Ç Label Smoothing –∫ —Ü–µ–ª–µ–≤—ã–º –º–µ—Ç–∫–∞–º.
        
        Args:
            x: –õ–æ–≥–∏—Ç—ã –º–æ–¥–µ–ª–∏ [batch_size, seq_len, vocab_size]
            target: –ò—Å—Ç–∏–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ [batch_size, seq_len]
            
        Returns:
            torch.Tensor: Loss value
        """
        assert x.size(1) == self.size
        true_dist = x.data.clone()
        true_dist.fill_(self.smoothing / (self.size - 2))
        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)
        true_dist[:, self.padding_idx] = 0
        mask = torch.nonzero(target.data == self.padding_idx)
        if mask.dim() > 0:
            true_dist.index_fill_(0, mask.squeeze(), 0.0)
        self.true_dist = true_dist
        return self.criterion(x, true_dist)


class NoamOpt:
    """–û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å warming-up."""
    def __init__(self, model_size, factor=2, warmup=4000, optimizer=None):
        self.optimizer = optimizer
        self._step = 0
        self.warmup = warmup
        self.factor = factor
        self.model_size = model_size
        self._rate = 0

    def step(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–∏—è."""
        self._step += 1
        rate = self.rate()
        for p in self.optimizer.param_groups:
            p['lr'] = rate
        self._rate = rate
        self.optimizer.step()

    def rate(self, step=None):
        """–í—ã—á–∏—Å–ª—è–µ—Ç —Ç–µ–∫—É—â–∏–π learning rate."""
        if step is None:
            step = self._step
        return self.factor * (self.model_size ** (-0.5) * 
                              min(step ** (-0.5), step * self.warmup ** (-1.5)))


def compute_rouge_scores(generated_texts, reference_texts):
    """
    –í—ã—á–∏—Å–ª—è–µ—Ç ROUGE –º–µ—Ç—Ä–∏–∫–∏ (–ó–∞–¥–∞–Ω–∏–µ 2).
    
    Args:
        generated_texts (list): –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        reference_texts (list): –≠—Ç–∞–ª–æ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        
    Returns:
        dict: ROUGE-1, ROUGE-2, ROUGE-L scores
    """
    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)
    
    rouge1_scores = []
    rouge2_scores = []
    rougeL_scores = []
    
    for gen, ref in zip(generated_texts, reference_texts):
        scores = scorer.score(ref, gen)
        rouge1_scores.append(scores['rouge1'].fmeasure)
        rouge2_scores.append(scores['rouge2'].fmeasure)
        rougeL_scores.append(scores['rougeL'].fmeasure)
    
    return {
        'rouge1': np.mean(rouge1_scores),
        'rouge2': np.mean(rouge2_scores),
        'rougeL': np.mean(rougeL_scores)
    }


def do_epoch(model, criterion, data_iter, optimizer=None, name=None, field=None, writer=None, epoch=None):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–Ω—É —ç–ø–æ—Ö—É –æ–±—É—á–µ–Ω–∏—è –∏–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏.
    
    Args:
        model: –ú–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        criterion: –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
        data_iter: –ò—Ç–µ—Ä–∞—Ç–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        optimizer: –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (None –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏)
        name: –ù–∞–∑–≤–∞–Ω–∏–µ —ç–ø–æ—Ö–∏ –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        field: Word field –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤
        writer: TensorBoard writer –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫
        epoch: –ù–æ–º–µ—Ä —ç–ø–æ—Ö–∏ –¥–ª—è TensorBoard
        
    Returns:
        tuple: (average_loss, rouge_scores)
    """
    is_train = optimizer is not None
    model.train(is_train)
    
    epoch_loss = 0
    total_tokens = 0
    
    # –î–ª—è ROUGE –º–µ—Ç—Ä–∏–∫
    generated_texts = []
    reference_texts = []
    
    with tqdm(data_iter, desc=name) as pbar:
        for i, batch in enumerate(pbar):
            source_inputs, target_inputs, target_outputs, source_mask, target_mask = convert_batch(
                batch, pad_idx=field.vocab.stoi['<pad>']
            )
            
            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
            output = model(source_inputs, target_inputs, source_mask, target_mask)
            
            # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–æ—Ç–µ—Ä—å
            loss = criterion(
                output.contiguous().view(-1, output.size(-1)),
                target_outputs.contiguous().view(-1)
            )
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ NaN
            if torch.isnan(loss):
                print(f"\n‚ùå NaN detected in loss at batch {i}!")
                print(f"Output stats: min={output.min():.4f}, max={output.max():.4f}, mean={output.mean():.4f}")
                print(f"Target stats: min={target_outputs.min()}, max={target_outputs.max()}")
                if is_train:
                    print("Skipping this batch...")
                    continue
                else:
                    break
            
            if is_train:
                optimizer.optimizer.zero_grad()
                loss.backward()
                
                # Gradient clipping –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –Ω–∞ NaN
                has_nan_grad = False
                for name, param in model.named_parameters():
                    if param.grad is not None and torch.isnan(param.grad).any():
                        print(f"\n‚ùå NaN gradient detected in {name}")
                        has_nan_grad = True
                        break
                
                if has_nan_grad:
                    print("Skipping optimizer step due to NaN gradients")
                    continue
                
                optimizer.step()
            
            # –ü–æ–¥—Å—á–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫
            n_tokens = (target_outputs != field.vocab.stoi['<pad>']).data.sum().item()
            epoch_loss += loss.item()
            total_tokens += n_tokens
            
            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ TensorBoard –∫–∞–∂–¥—ã–µ 100 –±–∞—Ç—á–µ–π
            if writer is not None and epoch is not None and i % 100 == 0:
                step = epoch * len(data_iter) + i
                current_loss = loss.item() / n_tokens if n_tokens > 0 else 0
                mode = 'train' if is_train else 'val'
                writer.add_scalar(f'Loss/{mode}_batch', current_loss, step)
                writer.add_scalar(f'Learning_Rate', optimizer._rate if is_train and optimizer else 0, step)
                
                # –õ–æ–≥–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
                if is_train:
                    total_norm = 0
                    for p in model.parameters():
                        if p.grad is not None:
                            param_norm = p.grad.data.norm(2)
                            total_norm += param_norm.item() ** 2
                    total_norm = total_norm ** (1. / 2)
                    writer.add_scalar(f'Gradients/total_norm', total_norm, step)
            
            # –î–ª—è ROUGE –º–µ—Ç—Ä–∏–∫ (–±–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ –±–∞—Ç—á–µ–π, —á—Ç–æ–±—ã –Ω–µ –∑–∞–º–µ–¥–ª—è—Ç—å)
            if i < 5 and field is not None:
                # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç—ã –¥–ª—è ROUGE
                pred_tokens = output.argmax(-1)
                for j in range(min(2, source_inputs.size(0))):  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2 –ø—Ä–∏–º–µ—Ä–∞ –∏–∑ –±–∞—Ç—á–∞
                    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
                    pred_seq = pred_tokens[j].cpu().numpy()
                    pred_words = [field.vocab.itos[idx] for idx in pred_seq if idx not in [
                        field.vocab.stoi['<pad>'], field.vocab.stoi['<s>'], field.vocab.stoi['</s>']
                    ]]
                    
                    # –î–µ–∫–æ–¥–∏—Ä—É–µ–º –∏—Å—Ç–∏–Ω–Ω—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
                    true_seq = target_outputs[j].cpu().numpy()
                    true_words = [field.vocab.itos[idx] for idx in true_seq if idx not in [
                        field.vocab.stoi['<pad>'], field.vocab.stoi['<s>'], field.vocab.stoi['</s>']
                    ]]
                    
                    generated_texts.append(' '.join(pred_words))
                    reference_texts.append(' '.join(true_words))
            
            current_loss = loss.item() / n_tokens if n_tokens > 0 else 0
            pbar.set_postfix(loss=current_loss, lr=optimizer._rate if is_train and optimizer else 0)
    
    # –í—ã—á–∏—Å–ª—è–µ–º ROUGE –º–µ—Ç—Ä–∏–∫–∏
    rouge_scores = {}
    if generated_texts and reference_texts:
        rouge_scores = compute_rouge_scores(generated_texts, reference_texts)
    
    avg_loss = epoch_loss / total_tokens if total_tokens > 0 else 0
    
    return avg_loss, rouge_scores


def fit(model, criterion, optimizer, train_iter, epochs_count=1, val_iter=None, field=None, log_dir=None, 
        checkpoint_dir='checkpoints', save_every=1, resume_from_checkpoint=True, 
        save_best_model=True, early_stopping_patience=None, use_pretrained=False):
    """
    –û–±—É—á–∞–µ—Ç –º–æ–¥–µ–ª—å —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤.
    
    Args:
        model: –ú–æ–¥–µ–ª—å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
        criterion: –§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
        optimizer: –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
        train_iter: –ò—Ç–µ—Ä–∞—Ç–æ—Ä —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        epochs_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö
        val_iter: –ò—Ç–µ—Ä–∞—Ç–æ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        field: Word field –¥–ª—è –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è
        log_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ª–æ–≥–æ–≤ TensorBoard
        checkpoint_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
        save_every: –°–æ—Ö—Ä–∞–Ω—è—Ç—å —á–µ–∫–ø–æ–∏–Ω—Ç –∫–∞–∂–¥—ã–µ N —ç–ø–æ—Ö
        resume_from_checkpoint: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        save_best_model: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ validation loss
        early_stopping_patience: –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ —É–ª—É—á—à–µ–Ω–∏–π (epochs)
        use_pretrained: –§–ª–∞–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        
    Returns:
        dict: –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
    """
    # –ü–æ–ª—É—á–∞–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏
    device = next(model.parameters()).device
    
    # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç
    start_epoch = 0
    history = {
        'train_losses': [],
        'val_losses': [],
        'train_rouge': [],
        'val_rouge': [],
        'tensorboard_log_dir': None
    }
    
    if resume_from_checkpoint:
        latest_checkpoint = find_latest_checkpoint(checkpoint_dir)
        if latest_checkpoint:
            start_epoch, history = load_checkpoint(latest_checkpoint, model, optimizer, device)
    
    # –°–æ–∑–¥–∞–µ–º TensorBoard writer
    if log_dir is None:
        # –ï—Å–ª–∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –ª–æ–≥–æ–≤
        if history.get('tensorboard_log_dir') and resume_from_checkpoint:
            log_dir = history['tensorboard_log_dir']
            print(f"üîÑ Resuming TensorBoard logging to existing directory: {log_dir}")
        else:
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å timestamp
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            model_type = "pretrained" if use_pretrained else "random"
            log_dir = f"runs/train_{model_type}_{timestamp}"
            print(f"üìä Creating new TensorBoard log directory: {log_dir}")
    
    writer = SummaryWriter(log_dir)
    history['tensorboard_log_dir'] = log_dir
    
    print(f"TensorBoard logs saved to: {log_dir}")
    print(f"Run 'tensorboard --logdir={log_dir}' to view logs")
    
    # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
    best_val_loss = float('inf')
    best_model_path = None
    epochs_without_improvement = 0
    
    if history['val_losses']:
        best_val_loss = min(history['val_losses'])
    
    # –õ–æ–≥–∏—Ä—É–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è)
    if start_epoch == 0:
        try:
            # –°–æ–∑–¥–∞–µ–º dummy input –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≥—Ä–∞—Ñ–∞ –º–æ–¥–µ–ª–∏
            vocab_size = len(field.vocab)
            dummy_src = torch.randint(1, vocab_size, (2, 10))
            dummy_tgt = torch.randint(1, vocab_size, (2, 8))
            dummy_src_mask = torch.ones(2, 1, 10).bool()
            dummy_tgt_mask = torch.ones(2, 1, 8).bool()
            
            device = next(model.parameters()).device
            dummy_src = dummy_src.to(device)
            dummy_tgt = dummy_tgt.to(device)
            dummy_src_mask = dummy_src_mask.to(device)
            dummy_tgt_mask = dummy_tgt_mask.to(device)
            
            writer.add_graph(model, (dummy_src, dummy_tgt, dummy_src_mask, dummy_tgt_mask))
        except Exception as e:
            print(f"Could not log model graph: {e}")
    
    for epoch in range(start_epoch, epochs_count):
        print(f"\nEpoch {epoch + 1}/{epochs_count}")
        
        # –û–±—É—á–µ–Ω–∏–µ
        train_loss, train_rouge_scores = do_epoch(
            model, criterion, train_iter, optimizer, 
            name=f"Train Epoch {epoch + 1}", field=field,
            writer=writer, epoch=epoch
        )
        history['train_losses'].append(train_loss)
        history['train_rouge'].append(train_rouge_scores)
        
        print(f"Train Loss: {train_loss:.4f}")
        if train_rouge_scores:
            print(f"Train ROUGE-1: {train_rouge_scores.get('rouge1', 0):.4f}, "
                  f"ROUGE-2: {train_rouge_scores.get('rouge2', 0):.4f}, "
                  f"ROUGE-L: {train_rouge_scores.get('rougeL', 0):.4f}")
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        val_loss = None
        val_rouge_scores = None
        if val_iter is not None:
            val_loss, val_rouge_scores = do_epoch(
                model, criterion, val_iter, 
                name=f"Val Epoch {epoch + 1}", field=field,
                writer=writer, epoch=epoch
            )
            history['val_losses'].append(val_loss)
            history['val_rouge'].append(val_rouge_scores)
            
            print(f"Val Loss: {val_loss:.4f}")
            if val_rouge_scores:
                print(f"Val ROUGE-1: {val_rouge_scores.get('rouge1', 0):.4f}, "
                      f"ROUGE-2: {val_rouge_scores.get('rouge2', 0):.4f}, "
                      f"ROUGE-L: {val_rouge_scores.get('rougeL', 0):.4f}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É–ª—É—á—à–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            if save_best_model and val_loss < best_val_loss:
                best_val_loss = val_loss
                epochs_without_improvement = 0
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
                best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'val_loss': val_loss,
                    'val_rouge': val_rouge_scores
                }, best_model_path)
                print(f"üíæ New best model saved! Val Loss: {val_loss:.4f}")
            else:
                epochs_without_improvement += 1
        
        # –õ–æ–≥–∏—Ä—É–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –≤ TensorBoard
        writer.add_scalar('Loss/train_epoch', train_loss, epoch)
        if val_loss is not None:
            writer.add_scalar('Loss/val_epoch', val_loss, epoch)
        
        if train_rouge_scores:
            for metric, value in train_rouge_scores.items():
                writer.add_scalar(f'ROUGE/train_{metric}', value, epoch)
        
        if val_rouge_scores:
            for metric, value in val_rouge_scores.items():
                writer.add_scalar(f'ROUGE/val_{metric}', value, epoch)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ (–≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã –≤–µ—Å–æ–≤)
        if epoch % 5 == 0:  # –ö–∞–∂–¥—ã–µ 5 —ç–ø–æ—Ö
            for name, param in model.named_parameters():
                if param.requires_grad:
                    writer.add_histogram(f'Parameters/{name}', param, epoch)
                    if param.grad is not None:
                        writer.add_histogram(f'Gradients/{name}', param.grad, epoch)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        if (epoch + 1) % save_every == 0 or epoch == epochs_count - 1:
            save_checkpoint(model, optimizer, epoch, history, checkpoint_dir)
            
            # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
            cleanup_old_checkpoints(checkpoint_dir, keep_last=3)
        
        # Early stopping
        if early_stopping_patience and epochs_without_improvement >= early_stopping_patience:
            print(f"\nüõë Early stopping triggered! No improvement for {early_stopping_patience} epochs.")
            print(f"Best validation loss: {best_val_loss:.4f}")
            break
    
    writer.close()
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö
    if best_model_path and os.path.exists(best_model_path):
        print(f"\n‚úÖ Training completed!")
        print(f"Best model saved at: {best_model_path}")
        print(f"Best validation loss: {best_val_loss:.4f}")
    
    return history


def save_training_plot(history, save_path='training_plot.png'):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è.
    
    Args:
        history (dict): –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        save_path (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞
    """
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
    
    # Loss plots
    epochs = range(1, len(history['train_losses']) + 1)
    ax1.plot(epochs, history['train_losses'], 'b-', label='Train Loss')
    if history['val_losses']:
        ax1.plot(epochs, history['val_losses'], 'r-', label='Val Loss')
    ax1.set_title('Training and Validation Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.legend()
    ax1.grid(True)
    
    # ROUGE-1 plots
    if history['train_rouge'] and any(r for r in history['train_rouge']):
        train_rouge1 = [r.get('rouge1', 0) for r in history['train_rouge']]
        ax2.plot(epochs, train_rouge1, 'b-', label='Train ROUGE-1')
        if history['val_rouge']:
            val_rouge1 = [r.get('rouge1', 0) for r in history['val_rouge']]
            ax2.plot(epochs, val_rouge1, 'r-', label='Val ROUGE-1')
        ax2.set_title('ROUGE-1 Scores')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('ROUGE-1')
        ax2.legend()
        ax2.grid(True)
    
    # ROUGE-2 plots
    if history['train_rouge'] and any(r for r in history['train_rouge']):
        train_rouge2 = [r.get('rouge2', 0) for r in history['train_rouge']]
        ax3.plot(epochs, train_rouge2, 'b-', label='Train ROUGE-2')
        if history['val_rouge']:
            val_rouge2 = [r.get('rouge2', 0) for r in history['val_rouge']]
            ax3.plot(epochs, val_rouge2, 'r-', label='Val ROUGE-2')
        ax3.set_title('ROUGE-2 Scores')
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('ROUGE-2')
        ax3.legend()
        ax3.grid(True)
    
    # ROUGE-L plots  
    if history['train_rouge'] and any(r for r in history['train_rouge']):
        train_rougeL = [r.get('rougeL', 0) for r in history['train_rouge']]
        ax4.plot(epochs, train_rougeL, 'b-', label='Train ROUGE-L')
        if history['val_rouge']:
            val_rougeL = [r.get('rougeL', 0) for r in history['val_rouge']]
            ax4.plot(epochs, val_rougeL, 'r-', label='Val ROUGE-L')
        ax4.set_title('ROUGE-L Scores')
        ax4.set_xlabel('Epoch')
        ax4.set_ylabel('ROUGE-L')
        ax4.legend()
        ax4.grid(True)
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"Training plots saved to {save_path}")


def save_checkpoint(model, optimizer, epoch, history, checkpoint_dir='checkpoints', filename=None):
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —á–µ–∫–ø–æ–∏–Ω—Ç –æ–±—É—á–µ–Ω–∏—è.
    
    Args:
        model: –ú–æ–¥–µ–ª—å PyTorch
        optimizer: –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (NoamOpt)
        epoch: –¢–µ–∫—É—â–∞—è —ç–ø–æ—Ö–∞
        history: –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        checkpoint_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
        filename: –ò–º—è —Ñ–∞–π–ª–∞ (–µ—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
        
    Returns:
        str: –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    os.makedirs(checkpoint_dir, exist_ok=True)
    
    if filename is None:
        filename = f'checkpoint_epoch_{epoch}.pth'
    
    checkpoint_path = os.path.join(checkpoint_dir, filename)
    
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.optimizer.state_dict(),
        'optimizer_step': optimizer._step,
        'optimizer_rate': optimizer._rate,
        'history': history,
        'timestamp': datetime.now().isoformat()
    }
    
    torch.save(checkpoint, checkpoint_path)
    print(f"Checkpoint saved: {checkpoint_path}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–∞–∫–∂–µ –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç
    latest_path = os.path.join(checkpoint_dir, 'latest_checkpoint.pth')
    torch.save(checkpoint, latest_path)
    
    return checkpoint_path


def load_checkpoint(checkpoint_path, model, optimizer, device=None):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —á–µ–∫–ø–æ–∏–Ω—Ç –æ–±—É—á–µ–Ω–∏—è.
    
    Args:
        checkpoint_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É —á–µ–∫–ø–æ–∏–Ω—Ç–∞
        model: –ú–æ–¥–µ–ª—å PyTorch
        optimizer: –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä (NoamOpt)
        device: –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ (cuda/mps/cpu)
        
    Returns:
        tuple: (start_epoch, history)
    """
    if not os.path.exists(checkpoint_path):
        print(f"Checkpoint not found: {checkpoint_path}")
        return 0, {
            'train_losses': [],
            'val_losses': [],
            'train_rouge': [],
            'val_rouge': [],
            'tensorboard_log_dir': None
        }
    
    print(f"Loading checkpoint: {checkpoint_path}")
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∏–ª–∏ CPU –∫–∞–∫ fallback
    map_location = device if device is not None else 'cpu'
    checkpoint = torch.load(checkpoint_path, map_location=map_location, weights_only=False)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–¥–µ–ª–∏
    model.load_state_dict(checkpoint['model_state_dict'])
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä–∞
    optimizer.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
    optimizer._step = checkpoint['optimizer_step']
    optimizer._rate = checkpoint['optimizer_rate']
    
    start_epoch = checkpoint['epoch'] + 1  # –ù–∞—á–∏–Ω–∞–µ–º —Å–æ —Å–ª–µ–¥—É—é—â–µ–π —ç–ø–æ—Ö–∏
    history = checkpoint['history']
    
    print(f"Checkpoint loaded from epoch {checkpoint['epoch']} on device: {map_location}")
    print(f"Resuming training from epoch {start_epoch}")
    
    return start_epoch, history


def find_latest_checkpoint(checkpoint_dir='checkpoints'):
    """
    –ù–∞—Ö–æ–¥–∏—Ç –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–µ–∫–ø–æ–∏–Ω—Ç –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
    
    Args:
        checkpoint_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏
        
    Returns:
        str or None: –ü—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —á–µ–∫–ø–æ–∏–Ω—Ç—É –∏–ª–∏ None
    """
    latest_path = os.path.join(checkpoint_dir, 'latest_checkpoint.pth')
    if os.path.exists(latest_path):
        return latest_path
    
    # –ò—â–µ–º –ø–æ –Ω–æ–º–µ—Ä–∞–º —ç–ø–æ—Ö
    if not os.path.exists(checkpoint_dir):
        return None
    
    checkpoint_files = [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_epoch_') and f.endswith('.pth')]
    if not checkpoint_files:
        return None
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É —ç–ø–æ—Ö–∏
    checkpoint_files.sort(key=lambda x: int(x.split('_')[2].split('.')[0]))
    return os.path.join(checkpoint_dir, checkpoint_files[-1])


def cleanup_old_checkpoints(checkpoint_dir='checkpoints', keep_last=3):
    """
    –£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ.
    
    Args:
        checkpoint_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏
        keep_last: –°–∫–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤ –æ—Å—Ç–∞–≤–∏—Ç—å
    """
    if not os.path.exists(checkpoint_dir):
        return
    
    checkpoint_files = [f for f in os.listdir(checkpoint_dir) 
                       if f.startswith('checkpoint_epoch_') and f.endswith('.pth')]
    
    if len(checkpoint_files) <= keep_last:
        return
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –Ω–æ–º–µ—Ä—É —ç–ø–æ—Ö–∏
    checkpoint_files.sort(key=lambda x: int(x.split('_')[2].split('.')[0]))
    
    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã
    for old_file in checkpoint_files[:-keep_last]:
        old_path = os.path.join(checkpoint_dir, old_file)
        os.remove(old_path)
        print(f"Removed old checkpoint: {old_path}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è."""
    # –ü–∞—Ä—Å–µ—Ä –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    parser = argparse.ArgumentParser(description='Train Transformer model for text summarization')
    parser.add_argument('--epochs', type=int, default=10, help='Number of training epochs')
    parser.add_argument('--no-resume', action='store_true', help='Start training from scratch (ignore checkpoints)')
    parser.add_argument('--checkpoint-dir', type=str, default='checkpoints', help='Directory for checkpoints')
    parser.add_argument('--save-every', type=int, default=1, help='Save checkpoint every N epochs')
    parser.add_argument('--early-stopping', type=int, default=None, help='Early stopping patience (epochs)')
    parser.add_argument('--no-pretrained', action='store_true', help='Force use of random embeddings')
    
    args = parser.parse_args()
    
    print("Starting training...")
    print(f"Arguments: {vars(args)}")
    
    # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ mps -> cuda -> cpu
    device = get_device()
    print(f"Using device: {device}")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    train_iter, test_iter, word_field = load_processed_data_iterators(device=device)
    vocab_size = len(word_field.vocab)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
    fasttext_path = 'src/embeddings/cc.ru.300.bin'
    use_pretrained = os.path.exists(fasttext_path) and not args.no_pretrained
    
    if use_pretrained:
        print(f"‚úì Found pretrained embeddings at {fasttext_path}")
        print("Training with pretrained Russian FastText embeddings (Task 6)")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ (300d)
        model = create_model_with_pretrained_embeddings(vocab_size, word_field, fasttext_path)
        model_size = 300
    else:
        if args.no_pretrained:
            print("‚ö† Using random embeddings (forced by --no-pretrained flag)")
        else:
            print("‚ö† Pretrained embeddings not found. Using random embeddings.")
            print("To use pretrained embeddings, run: python -m src.embeddings.download_embeddings")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å –æ–±—ã—á–Ω—ã–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏ (256d)
        model = create_model(vocab_size=vocab_size, d_model=256)
        model_size = 256
    
    model.to(device)
    
    print(f"Model created with d_model={model_size}")
    print(f"Total parameters: {sum(p.numel() for p in model.parameters()):,}")
    print(f"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
    
    # Label Smoothing Loss (–ó–∞–¥–∞–Ω–∏–µ 5)
    criterion = LabelSmoothingLoss(
        size=vocab_size, 
        padding_idx=word_field.vocab.stoi['<pad>'], 
        smoothing=0.1
    )
    
    # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä —Å —É—á–µ—Ç–æ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏
    if use_pretrained:
        # –ë–æ–ª–µ–µ –∫–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π learning rate –¥–ª—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        optimizer = NoamOpt(
            model_size=model_size, factor=1, warmup=4000,  # –£–º–µ–Ω—å—à–∏–ª–∏ factor —Å 2 –¥–æ 1
            optimizer=torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)
        )
        print("Using conservative learning rate for pretrained embeddings (factor=1)")
    else:
        optimizer = NoamOpt(
            model_size=model_size, factor=2, warmup=4000,
            optimizer=torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9)
        )
        print("Using standard learning rate for random embeddings (factor=2)")
    
    # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    os.makedirs('runs', exist_ok=True)
    os.makedirs(args.checkpoint_dir, exist_ok=True)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —á–µ–∫–ø–æ–∏–Ω—Ç—ã
    if not args.no_resume:
        latest_checkpoint = find_latest_checkpoint(args.checkpoint_dir)
        if latest_checkpoint:
            print(f"üîÑ Found existing checkpoint: {latest_checkpoint}")
            print("Training will resume from the last checkpoint.")
            print("Use --no-resume to start from scratch.")
        else:
            print("üÜï No existing checkpoints found. Starting fresh training.")
    else:
        print("üÜï Starting training from scratch (--no-resume flag)")
    
    # –û–±—É—á–µ–Ω–∏–µ —Å —á–µ–∫–ø–æ–∏–Ω—Ç–∞–º–∏
    history = fit(
        model=model,
        criterion=criterion,
        optimizer=optimizer,
        train_iter=train_iter,
        epochs_count=args.epochs,
        val_iter=test_iter,
        field=word_field,
        checkpoint_dir=args.checkpoint_dir,
        save_every=args.save_every,
        resume_from_checkpoint=not args.no_resume,
        save_best_model=True,
        early_stopping_patience=args.early_stopping,
        use_pretrained=use_pretrained
    )
    
    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    model_suffix = "_pretrained" if use_pretrained else "_random"
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    best_model_path = os.path.join(args.checkpoint_dir, 'best_model.pth')
    if os.path.exists(best_model_path):
        print(f"üì• Loading best model from {best_model_path}")
        best_checkpoint = torch.load(best_model_path, map_location=device, weights_only=False)
        model.load_state_dict(best_checkpoint['model_state_dict'])
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        torch.save(model.state_dict(), f'best_model{model_suffix}.pt')
        print(f"üíæ Best model saved as: best_model{model_suffix}.pt")
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        best_epoch = best_checkpoint['epoch']
        best_val_loss = best_checkpoint['val_loss']
        best_rouge = best_checkpoint.get('val_rouge', {})
        
        print(f"üìä Best model from epoch {best_epoch + 1}:")
        print(f"   Validation Loss: {best_val_loss:.4f}")
        if best_rouge:
            for metric, score in best_rouge.items():
                print(f"   {metric.upper()}: {score:.4f}")
    else:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –ª—É—á—à–µ–π –Ω–µ—Ç
        torch.save(model.state_dict(), f'best_model{model_suffix}.pt')
        print(f"üíæ Final model saved as: best_model{model_suffix}.pt")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥—Ä–∞—Ñ–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è
    save_training_plot(history, f'training_plot{model_suffix}.png')
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏
    model_info = {
        'use_pretrained': use_pretrained,
        'model_size': model_size,
        'vocab_size': vocab_size,
        'fasttext_path': fasttext_path if use_pretrained else None,
        'total_epochs': len(history['train_losses']),
        'final_train_loss': history['train_losses'][-1] if history['train_losses'] else None,
        'final_val_loss': history['val_losses'][-1] if history['val_losses'] else None,
        'final_rouge': history['val_rouge'][-1] if history['val_rouge'] else None,
        'best_val_loss': best_val_loss if 'best_val_loss' in locals() else None,
        'tensorboard_log_dir': history.get('tensorboard_log_dir'),
        'checkpoint_dir': args.checkpoint_dir,
        'training_args': vars(args)
    }
    
    with open(f'model_info{model_suffix}.json', 'w', encoding='utf-8') as f:
        json.dump(model_info, f, indent=2, ensure_ascii=False)
    
    print("\n" + "="*60)
    print("üéâ TRAINING COMPLETED!")
    print("="*60)
    print(f"Model type: {'Pretrained embeddings' if use_pretrained else 'Random embeddings'}")
    print(f"Total epochs trained: {len(history['train_losses'])}")
    print(f"Model saved as: best_model{model_suffix}.pt")
    print(f"Training plot saved as: training_plot{model_suffix}.png")
    print(f"Model info saved as: model_info{model_suffix}.json")
    print(f"Checkpoints saved in: {args.checkpoint_dir}/")
    print(f"TensorBoard logs: {history.get('tensorboard_log_dir')}")
    print(f"Run 'tensorboard --logdir={history.get('tensorboard_log_dir')}' to view training progress")
    
    # –ó–∞–¥–∞–Ω–∏–µ 6: –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if use_pretrained and model_info['final_rouge']:
        print("\n" + "="*60)
        print("TASK 6: Results with pretrained Russian embeddings")
        print("="*60)
        print(f"Final ROUGE scores:")
        for metric, score in model_info['final_rouge'].items():
            print(f"  {metric.upper()}: {score:.4f}")
        print(f"Final validation loss: {model_info['final_val_loss']:.4f}")
        if 'best_val_loss' in locals():
            print(f"Best validation loss: {best_val_loss:.4f}")
        print("\nTo compare with random embeddings, use --no-pretrained flag.")
    
    print("\nüí° Tips:")
    print("  - Resume training: python -m src.train")
    print("  - Start fresh: python -m src.train --no-resume")
    print("  - More epochs: python -m src.train --epochs 20")
    print("  - Early stopping: python -m src.train --early-stopping 5")


if __name__ == "__main__":
    main() 