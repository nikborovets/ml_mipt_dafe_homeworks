# Домашнее задание: распознавание лиц с помощью глубоких нейронных сетей

| Дедлайн | 31.05.2024 |
| :----: | :---: |
| Номер ДЗ | ``05``   |

- [Домашнее задание: распознавание лиц с помощью глубоких нейронных сетей](#домашнее-задание-распознавание-лиц-с-помощью-глубоких-нейронных-сетей)
  - [1. Основные шаги](#1-основные-шаги)
- [Минимальные требования](#минимальные-требования)
- [Идеи для реализации](#идеи-для-реализации)
  - [Полезные ссылки](#полезные-ссылки)
- [2. Рейтинг задания](#2-рейтинг-задания)
- [3. Форма отчетности](#3-форма-отчетности)
    - [3.1. Финальная отчетность](#31-финальная-отчетность)
    - [3.2. Опции](#32-опции)


В этом задании вы будете исследовать использование глубоких нейронных сетей для решения проблемы распознавания лиц. Цель заключается в обучении модели, которая способна идентифицировать людей по набору изображений лиц.

## 1. Основные шаги

1. **Сбор данных**: Соберите набор данных изображений лиц. Вы можете использовать существующие наборы данных, такие как [Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/) или [CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html), или создать свой собственный набор данных, используя инструменты, такие как [OpenCV](https://opencv.org/).
2. **Предварительная обработка данных**: Предварительно обработайте изображения, чтобы они подходили для обучения глубокой нейронной сети. Это может включать изменение размера, нормализацию и аугментацию.
3. **Выбор модели**: Выберите подходящую архитектуру глубокой нейронной сети для задачи распознавания лиц. Вы можете использовать заранее обученные модели, такие как [VGG Face](http://www.robots.ox.ac.uk/~vgg/software/vgg_face/) или [FaceNet](https://github.com/davidsandberg/facenet), или разработать свою собственную архитектуру.
4. **Обучение модели**: Обучите выбранную модель на предварительно обработанном наборе данных.
5. **Оценка модели**: Оцените обученную модель на тестовом наборе, чтобы измерить ее производительность. Вы можете использовать метрики, такие как точность, точность и полноту.
6. **Оптимизация модели**: Оптимизируйте модель для улучшения ее производительности. Это может включать настройку гиперпараметров, регуляризацию и дообучение.
7. **Развёртывание**: Разверните обученную модель. Это может включать интеграцию ее с веб-сервисом или мобильным приложением (или вызов через консоль).

# Минимальные требования

- Приведите демонстрацию решения в следующем виде. 
    1. На вход модели подается 1 ваше изображение и еще 15 тестовых изображений, из которых 10 других людей и 5 ваших изображений.
    2. Хотя бы в 6 из 10 случаев ваше решение должно определить, что на тестовых изображениях других людей изображены не вы.
    3. Хотя бы в 3 из 5 случаев ваше решение должно определить, что на тестовых изображениях с вами изображены именно вы.
    4. При этом не разрешается использовать в обучающей выборке ваше изображение и те 15 тестовых изображений.
    5. Во время демонстрации решения предусмотрите возможность, что вас попросят загрузить в демонстрацию новое 1 ваше изображение и 15 тестовых.

Требование к изображению
1. Изображение должно содержать посторонние предметы
2. Фон не однотонный и не однообразный
3. На изображении может быть расположено более одного человека

*Деплой модели в веб-сервис или приложение не является обязательным требованием.*

----

# Идеи для реализации

- Экспериментируйте с разными архитектурами глубоких нейронных сетей и сравнивайте их производительность.
- Экспериментируйте с Siamese Neural Networks, которые могут изучать функцию сходства между двумя изображениями и могут быть полезны для задач верификации лиц.
- Исследуйте ArcFace loss, которые являются функцией потерь, специально разработанной для задач распознавания лиц и показала многообещающие результаты.
- Исследуйте self-supervised learning techniques, которые могут учиться на неразмеченных данных и могут улучшить производительность модели.
- Рассмотрите использование metric learning для изучения пространства признаков, где расстояния между изображениями соответствуют их сходству в терминах идентичности.
- Обучите модель на крупномасштабном наборе данных, таком как MS-Celeb-1M или VGGFace2, и исследуйте влияние размера данных на производительность модели.
- Исследуйте различные методы аугментации данных, чтобы улучшить устойчивость модели.
- Исследуйте использование передачи обучения для обучения модели на более маленьком наборе данных.
- Рассмотрите возможность идентификации лиц вне заданного обучающего набора данных.
- Создайте мобильное или веб приложение, которое использует модель распознавания лиц для идентификации в режиме реального времени.
- Обучите модель на конкретном подмножестве набора данных, таком как знаменитости или исторические личности.

----

Еще несколько вариантов реализации:

1. **Вариант 1**: Используйте заранее обученную модель FaceNet для распознавания лиц в наборе данных Labeled Faces in the Wild с помощью PyTorch. Оцените производительность модели на тестовом наборе и оптимизируйте ее, используя техники дообучения и регуляризации.
2. **Вариант 2**: Разработайте и реализуйте собственную архитектуру глубокой нейронной сети для распознавания лиц с помощью PyTorch. Обучите модель на более маленьком наборе данных, таком как набор данных AT&T Faces, и оцените ее производительность. Экспериментируйте с различными техниками регуляризации, такими как отсев и L2-регуляризация, чтобы улучшить обобщающую способность модели.
3. **Вариант 3**: Обучите Siamese Neural Network с помощью PyTorch, чтобы изучить функцию сходства между двумя изображениями для задач верификации лиц. Используйте набор данных Labeled Faces in the Wild для обучения и оценки модели, и оптимизируйте ее, используя техники регуляризации и настройки гиперпараметров.
4. **Вариант 4**: Исследуйте потери ArcFace, функцию потерь, специально разработанную для задач распознавания лиц, с помощью PyTorch. Обучите модель, используя потери ArcFace, и сравните ее производительность с моделью, обученной с помощью традиционных потерь softmax. Оптимизируйте модель, используя техники дообучения и передачи обучения.
5. **Вариант 5**: Обучите модель на крупномасштабном наборе данных, таком как MS-Celeb-1M или VGGFace2, и исследуйте влияние размера данных на производительность модели. Экспериментируйте с различными методами аугментации данных, такими как поворот, трансляция и переворот, чтобы улучшить устойчивость модели.

Надеюсь, эти варианты планов будут полезны! Дайте мне знать, если у вас есть какие-либо вопросы или вам нужна дополнительная помощь.

## Полезные ссылки

- **[Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/)**: A dataset for collecting face images.
- **[CelebA](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)**: A dataset for collecting face images.
- **[OpenCV](https://opencv.org/)**: A library for image processing.
- **[VGG Face](http://www.robots.ox.ac.uk/~vgg/software/vgg_face/)**: A pre-trained model for face recognition.
- **[FaceNet](https://github.com/davidsandberg/facenet)**: A pre-trained model for face recognition.
- **[DeepFace](https://research.fb.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/)**: A research paper on face recognition.
- **[DeepID](https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Sun_Deep_Identification_Using_2014_CVPR_paper.pdf)**: A research paper on face recognition.
- **[OpenFace](https://cmusatyalab.github.io/openface/)**: An open-source face recognition toolkit.

Вот несколько полезных ссылок для быстрого прототипирования мобильных приложений на Python:

- [Kivy](https://kivy.org/#home): библиотека Python с открытым исходным кодом для быстрого развития приложений, которые используют инновационные пользовательские интерфейсы, такие как приложения с мультитачем.
- [BeeWare](https://beeware.org/): набор инструментов для разработки мобильных и настольных приложений с помощью Python.
- [Python для Android](https://github.com/kivy/python-for-android): набор инструментов для создания приложений Python для Android.
- [PyMob](https://www.pymob.org/): платформа, которая позволяет разработчикам писать мобильные приложения на Python, которые работают нативно на устройствах Android и iOS.

Вот несколько полезных ссылок для развертывания моделей PyTorch на веб-сервере:

- [PyTorch Serving](https://pytorch.org/serve/): простой и гибкий способ развертывания моделей PyTorch в масштабе.
- [FastAPI](https://fastapi.tiangolo.com/): современный, быстрый (высокопроизводительный) веб-фреймворк для создания API с помощью Python 3.6+.
- [Flask](https://flask.palletsprojects.com/en/2.0.x/): легкий веб-фреймворк для создания веб-приложений на Python.
- [Django](https://www.djangoproject.com/): высокоуровневый Python веб-фреймворк, который способствует быстрому развитию и чистому, прагматичному дизайну.
- [Heroku](https://www.heroku.com/): облачная платформа, которая позволяет развертывать, управлять и масштабировать приложения, написанные на Python и других языках.

# 2. Рейтинг задания

1. Финальная отчетность предоставлена в полном объеме и точность решения выше бейзлайна - 70%.
2. Выполнены дополнительные условия к исходному коду - до 30%.

# 3. Форма отчетности

### 3.1. Финальная отчетность

Требуется отправить в форму для сдачи задания архив.

**Требование к наименованию архива.**
1. Название должно быть в виде ``<name>-hw<number>.zip``, где
   - ``<name>`` - фамилия и инициалы на латинице, например ``PetrovII``;
   - ``<number>`` - порядковый номер домашнего задания, например ``02``;
   - пример полного имени архива ``PetrovII-hw01.zip``.

**Требование к содержанию архива.**
1. Графики обучения (функция ошибки, метрики и другие данные). Допустимо сгенерировать отчетность и сформировать pdf файл или веб-ссылку из таких приложений как wandb, neptune и тд.
2. Веса обученной модели в формате ``.pt``.
3. Весь исходный код обученной модели.
4. Файл requirements.txt для настройки окружения.
5. Файл с результатом предсказания на тестовой выборке - для 10 примеров.
6. Описание состава команды, если проект выполнен в команде.

**Требования к исходному коду.**
1. Код должен содержать описание, функцию или классы для воспроизведения файла обученной модели. 
2. Код должен содержать описание, функцию или класс для загрузки обученной модели и формирования предсказания для тестовой выборки.
3. **Запрещается делиться исходным кодом** с другими участникам или командам. В случае нарушения данного требования задание **может быть аннулировано**. 

**Требование к описанию состава команды.**
1. Приведены ФИО всех участников команды.
2. Указаны роли и достижения каждого члена команды.
3. Каждый член команды должен уметь ответить по содержанию всей работы. Качество решения задачи отдельных членов команды в ходе проверки определяется индивидуально
4. Оценка каждого члена команды зависит от качестве решения задачи в целом.

### 3.2. Опции

**Решение в командах.** Для решения задачи можно объединяться в команды. 
1. Размер команды - не более 3 человек.
2. Результаты оценки будут дублироваться на всю команду.
3. Команду нельзя менять в ходе решения задачи.
4. Команду можно менять между домашними заданиями.

**Описание к исходному коду.** Исходный код и его описание может быть направлено в виде ссылки на репозиторий в gitlab или github.

**Дополнительные требования к исходному коду.** Баллы будет присвоены за реализацию следующих пунктов.
1. Приложены тесты к исходному коду в частях: проверка датасета, проверка пайплайна обучения, проверка метрики и функции ошибки.
2. Приложен пайплайн dvc.
3. Код реализован в виде отдельный .py файлов.
4. Приложены make команды для запуска отдельных этапов выполнения вашего кода.
